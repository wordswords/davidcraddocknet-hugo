<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Web-Scraping on DavidCraddock.net</title>
    <link>https://davidcraddock.net/category/web-scraping/</link>
    <description>Recent content in Web-Scraping on DavidCraddock.net</description>
    <generator>Hugo -- 0.134.1</generator>
    <language>en</language>
    <lastBuildDate>Wed, 07 Sep 2011 18:35:17 +0000</lastBuildDate>
    <atom:link href="https://davidcraddock.net/category/web-scraping/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>JSoup Method for Page Scraping</title>
      <link>https://davidcraddock.net/2011/09/07/jsoup-method-for-page-scraping/</link>
      <pubDate>Wed, 07 Sep 2011 18:35:17 +0000</pubDate>
      <guid>https://davidcraddock.net/2011/09/07/jsoup-method-for-page-scraping/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://davidcraddock.net/wp-content/uploads/2011/09/soup.jpg&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://davidcraddock.net/wp-content/uploads/2011/09/soup.jpg&#34; alt=&#34;Soup bowl&#34;  /&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m currently in the process of writing a web scraper for the forums on &lt;a href=&#34;http://www.gaiaonline.com/forum&#34; title=&#34;Gaia Online&#34;&gt;Gaia Online&lt;/a&gt;. Previously, I used to use Python to develop web scrapers, with the very handy Python library &lt;a href=&#34;http://www.crummy.com/software/BeautifulSoup/&#34; title=&#34;BeautifulSoup&#34;&gt;BeautifulSoup&lt;/a&gt;. Java has an equivalent called JSoup.&lt;/p&gt;
&lt;p&gt;Here I have written a class which is extended by each class in my project that wants to scrape HTML. This &amp;lsquo;Scraper&amp;rsquo; class deals with the fetching of the HTML and converting it into a JSoup tree to be navigated and have the data picked out of. It advertises itself as a &amp;lsquo;web spider&amp;rsquo; type of web agent and also adds a 0-7 second random wait before fetching the page to make sure it isn&amp;rsquo;t used to overload a web server. It also converts the entire page to ASCII, which may not be the best thing to do for multi-language web pages, but certainly has made the scraping of the English language site Gaia Online much easier.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scraping Gumtree Property Adverts with Python and BeautifulSoup</title>
      <link>https://davidcraddock.net/2011/05/01/scraping-gumtree-property-adverts-with-python-and-beautifulsoup/</link>
      <pubDate>Sun, 01 May 2011 14:07:02 +0000</pubDate>
      <guid>https://davidcraddock.net/2011/05/01/scraping-gumtree-property-adverts-with-python-and-beautifulsoup/</guid>
      <description>&lt;p&gt;I am moving to Manchester soon, and so I thought I&amp;rsquo;d get an idea of the housing market there by scraping all the Manchester Gumtree property adverts into a MySQL database. Once in the database, I could do things like find the average monthly price for a 2 bedroom flat in an area, and spot bargains through using standard deviation from the mean on the price through using simple SQL queries via &lt;a href=&#34;http://www.phpmyadmin.net/home_page/index.php&#34;&gt;phpMyAdmin&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
