<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Linux on DavidCraddock.net</title>
    <link>http://192.168.1.50:9796/tag/linux/</link>
    <description>Recent content in Linux on DavidCraddock.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 24 Sep 2022 17:39:06 +0000</lastBuildDate><atom:link href="http://192.168.1.50:9796/tag/linux/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Google Drive Backup using Rclone</title>
      <link>http://192.168.1.50:9796/2022/09/24/google-drive-backup-using-rclone/</link>
      <pubDate>Sat, 24 Sep 2022 17:39:06 +0000</pubDate>
      
      <guid>http://192.168.1.50:9796/2022/09/24/google-drive-backup-using-rclone/</guid>
      <description>For 8 TB of data storage on Google Drive, plus my own Google organization, I am paying £30/month, which is a pretty good deal.
I wanted to use this space for backing up my NAS, but it was proving difficult. The program I was recommended for Linux backup, Duplicati, was not the best for this purpose. My backup runs would not complete, they would be slow, and full of syncing errors.</description>
      <content:encoded><![CDATA[<p>For 8 TB of data storage on Google Drive, plus my own Google organization, I am paying £30/month, which is a pretty good deal.</p>
<p>I wanted to use this space for backing up my NAS, but it was proving difficult. The program I was recommended for Linux backup, Duplicati, was not the best for this purpose. My backup runs would not complete, they would be slow, and full of syncing errors.</p>
<p>Until I discovered rclone.</p>
<p>rclone was much better than Duplicati at backing up my NAS to Google Drive.</p>
<p>This is the script I use to sync the NAS content to Google Drive: <a href="https://github.com/wordswords/dotfiles/blob/568a8768154de8609a01b26560373ec5ca0eab85/bin/rclone-backup.sh">https://github.com/wordswords/dotfiles/blob/568a8768154de8609a01b26560373ec5ca0eab85/bin/rclone-backup.sh</a></p>
<p>It works just like rsync, but with a progress indicator. I&rsquo;ve added it to my crontab and it syncs everything up weekly.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Setting up Kindlefire HDX for Development under Ubuntu 12.04</title>
      <link>http://192.168.1.50:9796/2014/02/10/kindlefire-hdx-under-ubuntu-12-04/</link>
      <pubDate>Mon, 10 Feb 2014 15:28:45 +0000</pubDate>
      
      <guid>http://192.168.1.50:9796/2014/02/10/kindlefire-hdx-under-ubuntu-12-04/</guid>
      <description>I wanted to get a Kindlefire HDX running under Ubuntu 12.04 with adb.
First I needed to setup the udev rules:
1. Edit /etc/udev/rules.d/51-android.rules as root, and add the following line (create this file if it does not exist):
SUBSYSTEM==&amp;#34;usb&amp;#34;, ATTRS{idVendor}==&amp;#34;1949&amp;#34;, MODE=&amp;#34;0666&amp;#34; 2. Change the permission of this file by executing the following command as root:
chmod a+r /etc/udev/rules.d/51-android.rules 3. Reload the rules by executing the following command as root:</description>
      <content:encoded><![CDATA[<p>I wanted to get a Kindlefire HDX running under Ubuntu 12.04 with adb.</p>
<p>First I needed to setup the udev rules:</p>
<p>1. Edit /etc/udev/rules.d/51-android.rules as root, and add the following line (create this file if it does not exist):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>SUBSYSTEM==&#34;usb&#34;, ATTRS{idVendor}==&#34;1949&#34;, MODE=&#34;0666&#34;
</span></span></code></pre></div><p>2. Change the permission of this file by executing the following command as root:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>chmod a+r /etc/udev/rules.d/51-android.rules
</span></span></code></pre></div><p>3. Reload the rules by executing the following command as root:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-gdscript3" data-lang="gdscript3"><span style="display:flex;"><span>udevadm control <span style="color:#f92672">--</span>reload<span style="color:#f92672">-</span>rules
</span></span></code></pre></div><p>4. Run these commands to restart adb:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>adb kill-server
</span></span><span style="display:flex;"><span>adb start-server
</span></span></code></pre></div><p>5. Now when I run</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>lsusb
</span></span></code></pre></div><p>I can see the device listed.</p>
<p>6. Next I needed to enable adb access on the Kindlefire HDX device itself by going to <strong>Settings -&gt; Device -&gt; Enable ADB</strong>.</p>
<p>7. Finally I could run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>adb devices
</span></span></code></pre></div><p>within Ubuntu and have it recognise the Kindlefire HDX.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>How to remove nano, vim and other editors&#39; backup files out of a directory tree</title>
      <link>http://192.168.1.50:9796/2010/03/22/how-to-remove-nano-vim-and-other-editors-backup-files-out-of-a-directory-tree/</link>
      <pubDate>Mon, 22 Mar 2010 20:49:20 +0000</pubDate>
      
      <guid>http://192.168.1.50:9796/2010/03/22/how-to-remove-nano-vim-and-other-editors-backup-files-out-of-a-directory-tree/</guid>
      <description>Linux command-line editors such as nano and vim often, by default, create backup files with the prefix of &amp;ldquo;&amp;rdquo;. I.e, if I created a file called /home/david/myfile, then nano would create a backup in /home/david/myfile. Sometimes it doesn&amp;rsquo;t delete them either, so you&amp;rsquo;re left with a bunch of backup files all over the place, especially if you&amp;rsquo;re editing a lot on a directory tree full of source code.
Those stray backup files make directory listings confusing, and also add unnecessary weight to the commits on source control systems such as svn, cvs, git.</description>
      <content:encoded><![CDATA[<p>Linux command-line editors such as nano and vim often, by default, create backup files with the prefix of &ldquo;<del>&rdquo;. I.e, if I created a file called /home/david/myfile, then nano would create a backup in /home/david/myfile</del>. Sometimes it doesn&rsquo;t delete them either, so you&rsquo;re left with a bunch of backup files all over the place, especially if you&rsquo;re editing a lot on a directory tree full of source code.</p>
<p>Those stray backup files make directory listings confusing, and also add unnecessary weight to the commits on source control systems such as svn, cvs, git.. etc. If you&rsquo;re working on a programming team with other people, then it causes further problems and confusion, because person A&rsquo;s editor can accidentally load person B&rsquo;s backup file.. etc etc. Nightmare.</p>
<p>So instruct your editor, or the programming team you&rsquo;re working with, not to drop these backup files. You can configure most editors to change the place where the editor drops its backup files, so you could store all your backup files in a subdirectory of your home directory, for example, if needed. However I always set my editors not to leave backup files about.</p>
<p>Once you know that new backup files will not be created, view the current list of backup files, along with the user that created them.. so you know who&rsquo;s been creating the backup files and when, etc:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>find . -name &#39;*~&#39; -type f -exec ls -al {}  ;
</span></span></code></pre></div><p>Then archive the stray backup files, with this command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>find . -name &#39;*~&#39; -type f -exec mv -i {} ./archived-backups ;
</span></span></code></pre></div><p>That will find all backup files in the current directory and below, and move them all to a subdirectory in the current directory called &lsquo;archived-backups&rsquo;. This is a fairly safe find/exec command, because with the -i switch, mv will not &lsquo;clobber&rsquo;. This means If you have two backup files, one in /opt/code/index~ and one in /opt/code/bla/bla/index~, they will not &lsquo;clobber&rsquo;, or overwrite each other automatically when moved into the new directory. You will be informed of any conflicts present so you can resolve them yourself.</p>
<p>However in practice I usually omit the &lsquo;-i&rsquo; switch and let them clobber each other, because I usually end up deleting the ./archived-backups/ directory very quickly after that anyway.</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
