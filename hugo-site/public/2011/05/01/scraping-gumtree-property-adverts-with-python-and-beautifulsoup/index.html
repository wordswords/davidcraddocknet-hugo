<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=9796&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Scraping Gumtree Property Adverts with Python and BeautifulSoup | DavidCraddock.net</title>
<meta name="keywords" content="">
<meta name="description" content="I am moving to Manchester soon, and so I thought I&rsquo;d get an idea of the housing market there by scraping all the Manchester Gumtree property adverts into a MySQL database. Once in the database, I could do things like find the average monthly price for a 2 bedroom flat in an area, and spot bargains through using standard deviation from the mean on the price through using simple SQL queries via phpMyAdmin.">
<meta name="author" content="">
<link rel="canonical" href="http://192.168.1.50:9796/2011/05/01/scraping-gumtree-property-adverts-with-python-and-beautifulsoup/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.7da7716a1f2d0725f74c6ae7f8d6adafc43aabe2b366b65bfbf433448e2a2001.css" integrity="sha256-fadxah8tByX3TGrn&#43;Natr8Q6q&#43;KzZrZb&#43;/QzRI4qIAE=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://192.168.1.50:9796/favicon.ico">
<link rel="apple-touch-icon" href="http://192.168.1.50:9796/apple-touch-icon.png">
<link rel="alternate" hreflang="en" href="http://192.168.1.50:9796/2011/05/01/scraping-gumtree-property-adverts-with-python-and-beautifulsoup/">

<meta name="twitter:title" content="Scraping Gumtree Property Adverts with Python and BeautifulSoup | DavidCraddock.net" />
<meta name="twitter:description" content="I am moving to Manchester soon, and so I thought I&rsquo;d get an idea of the housing market there by scraping all the Manchester Gumtree property adverts into a MySQL database. Once in the database, I could do things like find the average monthly price for a 2 bedroom flat in an area, and spot bargains through using standard deviation from the mean on the price through using simple SQL queries via phpMyAdmin." />
<meta property="og:title" content="Scraping Gumtree Property Adverts with Python and BeautifulSoup | DavidCraddock.net" />
<meta property="og:description" content="I am moving to Manchester soon, and so I thought I&rsquo;d get an idea of the housing market there by scraping all the Manchester Gumtree property adverts into a MySQL database. Once in the database, I could do things like find the average monthly price for a 2 bedroom flat in an area, and spot bargains through using standard deviation from the mean on the price through using simple SQL queries via phpMyAdmin." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://192.168.1.50:9796/2011/05/01/scraping-gumtree-property-adverts-with-python-and-beautifulsoup/" />
<meta property="article:section" content="posts" />
  <meta property="article:published_time" content="2011-05-01T14:07:02&#43;00:00" />
  <meta property="article:modified_time" content="2011-05-01T14:07:02&#43;00:00" />


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://192.168.1.50:9796/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Scraping Gumtree Property Adverts with Python and BeautifulSoup",
      "item": "http://192.168.1.50:9796/2011/05/01/scraping-gumtree-property-adverts-with-python-and-beautifulsoup/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Scraping Gumtree Property Adverts with Python and BeautifulSoup | DavidCraddock.net",
  "name": "Scraping Gumtree Property Adverts with Python and BeautifulSoup",
  "description": "I am moving to Manchester soon, and so I thought I\u0026rsquo;d get an idea of the housing market there by scraping all the Manchester Gumtree property adverts into a MySQL database. Once in the database, I could do things like find the average monthly price for a 2 bedroom flat in an area, and spot bargains through using standard deviation from the mean on the price through using simple SQL queries via phpMyAdmin.",
  "keywords": [
    
  ],
  "wordCount" : "1456",
  "inLanguage": "en",
  "datePublished": "2011-05-01T14:07:02Z",
  "dateModified": "2011-05-01T14:07:02Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://192.168.1.50:9796/2011/05/01/scraping-gumtree-property-adverts-with-python-and-beautifulsoup/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "DavidCraddock.net",
    "logo": {
      "@type": "ImageObject",
      "url": "http://192.168.1.50:9796/favicon.ico"
    }
  }
}
</script>
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary-bg: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list-page {
                background: var(--theme);
            }

            .list-page:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list-page:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

</head>

<body class=" type-posts kind-page layout-" id="top"><script data-no-instant>
function switchTheme(theme) {
  switch (theme) {
    case 'light':
      document.body.classList.remove('dark');
      break;
    case 'dark':
      document.body.classList.add('dark');
      break;
    
    default:
      if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
      }
  }
}

function isDarkTheme() {
  return document.body.className.includes("dark");
}

function getPrefTheme() {
  return localStorage.getItem("pref-theme");
}

function setPrefTheme(theme) {
  switchTheme(theme)
  localStorage.setItem("pref-theme", theme);
}

const toggleThemeCallbacks = {}
toggleThemeCallbacks['main'] = (isDark) => {
  
  if (isDark) {
    setPrefTheme('light');
  } else {
    setPrefTheme('dark');
  }
}




window.addEventListener('toggle-theme', function() {
  
  const isDark = isDarkTheme()
  for (const key in toggleThemeCallbacks) {
    toggleThemeCallbacks[key](isDark)
  }
});


function toggleThemeListener() {
  
  window.dispatchEvent(new CustomEvent('toggle-theme'));
}

</script>
<script>
  
  (function() {
    const defaultTheme = 'auto';
    const prefTheme = getPrefTheme();
    const theme = prefTheme ? prefTheme : defaultTheme;

    switchTheme(theme);
  })();
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://192.168.1.50:9796/" accesskey="h" title="DavidCraddock.net (Alt + H)">DavidCraddock.net</a>
            <span class="logo-switches">
            </span>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main post">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://192.168.1.50:9796/">Home</a>&nbsp;Â»&nbsp;<a href="http://192.168.1.50:9796/posts/">Posts</a></div><h1 class="post-title">Scraping Gumtree Property Adverts with Python and BeautifulSoup</h1>
    <div class="post-meta"><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select: text;"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select: text;"></rect><line x1="16" y1="2" x2="16" y2="6" style="user-select: text;"></line><line x1="8" y1="2" x2="8" y2="6" style="user-select: text;"></line><line x1="3" y1="10" x2="21" y2="10" style="user-select: text;"></line></svg>
  <span>May 1, 2011</span></span><span class="meta-item">
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><circle cx="12" cy="12" r="9"></circle><polyline points="12 7 12 12 15 15"></polyline></svg>
  <span>7 min</span></span>

      
      
    </div>
  </header> 

  <div class="post-content"><p>I am moving to Manchester soon, and so I thought I&rsquo;d get an idea of the housing market there by scraping all the Manchester Gumtree property adverts into a MySQL database. Once in the database, I could do things like find the average monthly price for a 2 bedroom flat in an area, and spot bargains through using standard deviation from the mean on the price through using simple SQL queries via <a href="http://www.phpmyadmin.net/home_page/index.php">phpMyAdmin</a>.</p>
<p>I really like the Python library <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a> for writing scrapers, there is also a Java version called <a href="http://jsoup.org/">JSoup</a>. BeautifulSoup does a really good job of tolerating markup mistakes in the input data, and transforms a page into a tree structure that is easy to work with.</p>
<p>I chose the following layout for the program:</p>
<p><strong>advert.py</strong> - Stores all information about each property advert, with a &lsquo;save&rsquo; method that inserts the data into the mysql database
<strong>listing.py</strong> - Stores all the information on each listing page, which is broken down into links for specific adverts, and also the link to the next listing page in the sequence (ie: the &rsquo;next page&rsquo; link)
<strong>scrapeAdvert.py</strong> - When given an advert URL, this creates and populates an advert object
<strong>scrapeListing.py</strong> - When given a listing URL, this creates and populates a listing object
<strong>scrapeSequence.py</strong> - This walks through a series of listings, calling scrapeListing and scrapeAdvert for all of them, and finishes when there are no more listings in the sequence to scrape</p>
<p>Here is the MySQL table I created for this project (which you will have to setup if you want to run the scraper):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#75715e">--
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">-- Database: `manchester`
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">--
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">-- --------------------------------------------------------
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">--
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">-- Table structure for table `adverts`
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">--
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">CREATE TABLE IF NOT EXISTS `adverts` (
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#f92672">`</span>url<span style="color:#f92672">`</span> <span style="color:#66d9ef">varchar</span>(<span style="color:#ae81ff">255</span>) <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">`</span>title<span style="color:#f92672">`</span> <span style="color:#66d9ef">text</span> <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">`</span>pricePW<span style="color:#f92672">`</span> <span style="color:#66d9ef">int</span>(<span style="color:#ae81ff">10</span>) <span style="color:#66d9ef">unsigned</span> <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">`</span>pricePCM<span style="color:#f92672">`</span> <span style="color:#66d9ef">int</span>(<span style="color:#ae81ff">11</span>) <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">`</span>location<span style="color:#f92672">`</span> <span style="color:#66d9ef">text</span> <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">`</span>dateAvailable<span style="color:#f92672">`</span> <span style="color:#66d9ef">date</span> <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">`</span>propertyType<span style="color:#f92672">`</span> <span style="color:#66d9ef">text</span> <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">`</span>bedroomNumber<span style="color:#f92672">`</span> <span style="color:#66d9ef">int</span>(<span style="color:#ae81ff">11</span>) <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">`</span>description<span style="color:#f92672">`</span> <span style="color:#66d9ef">text</span> <span style="color:#66d9ef">NOT</span> <span style="color:#66d9ef">NULL</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">PRIMARY</span> <span style="color:#66d9ef">KEY</span> (<span style="color:#f92672">`</span>url<span style="color:#f92672">`</span>)
</span></span><span style="display:flex;"><span>) <span style="color:#66d9ef">ENGINE</span><span style="color:#f92672">=</span>MyISAM <span style="color:#66d9ef">DEFAULT</span> <span style="color:#66d9ef">CHARSET</span><span style="color:#f92672">=</span>latin1;
</span></span></code></pre></div><p>PricePCM is price per calendar month, PricePW is price per week. Usually each advert with have one or the other specified.</p>
<p><strong>advert.py:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>import MySQLdb
</span></span><span style="display:flex;"><span>import chardet
</span></span><span style="display:flex;"><span>import sys
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>class advert:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        url = &#34;&#34;
</span></span><span style="display:flex;"><span>        title = &#34;&#34;
</span></span><span style="display:flex;"><span>        pricePW = 0
</span></span><span style="display:flex;"><span>        pricePCM = 0
</span></span><span style="display:flex;"><span>        location = &#34;&#34;
</span></span><span style="display:flex;"><span>        dateAvailable = &#34;&#34;
</span></span><span style="display:flex;"><span>        propertyType = &#34;&#34;
</span></span><span style="display:flex;"><span>        bedroomNumber = 0
</span></span><span style="display:flex;"><span>        description = &#34;&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def save(self):
</span></span><span style="display:flex;"><span>                # you will need to change the following to match your mysql credentials:
</span></span><span style="display:flex;"><span>                db=MySQLdb.connect(&#34;localhost&#34;,&#34;root&#34;,&#34;secret&#34;,&#34;manchester&#34;)
</span></span><span style="display:flex;"><span>                c=db.cursor()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                self.description = unicode(self.description, errors=&#39;replace&#39;)
</span></span><span style="display:flex;"><span>                self.description = self.description.encode(&#39;ascii&#39;,&#39;ignore&#39;)
</span></span><span style="display:flex;"><span>                # TODO: might need to convert the other strings in the advert if there are any unicode conversetion errors
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                sql = &#34;INSERT INTO adverts (url,title,pricePCM,pricePW,location,dateAvailable,propertyType,bedroomNumber,description) VALUES(&#39;&#34;+self.url+&#34;&#39;,&#39;&#34;+self.title+&#34;&#39;,&#34;+str(self.pricePCM)+&#34;,&#34;+str(self.pricePW)+&#34;,&#39;&#34;+self.location+&#34;&#39;,&#39;&#34;+self.dateAvailable+&#34;&#39;,&#39;&#34;+self.propertyType+&#34;&#39;,&#34;+str(self.bedroomNumber)+&#34;,&#39;&#34;+self.description+&#34;&#39; )&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                c.execute(sql)
</span></span></code></pre></div><p>In advert.py we convert the unicode output that BeautifulSoup gives us into plain ASCII so that we can put it in the MySQL database without any problems. I could have used Unicode in the database as well, but the chances of really needing Unicode for representing Gumtree ads is quite slim. If you intend to use this code then you will also want to enter the MySQL credentials for your database.</p>
<p><strong>listing.py:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>class listing:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        url=&#34;&#34;
</span></span><span style="display:flex;"><span>        adverturls=[]
</span></span><span style="display:flex;"><span>        nextLink=&#34;&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def addAdvertURL(self,url):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                self.adverturls.append(url)
</span></span></code></pre></div><p><strong>scrapeAdvert.py:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>from BeautifulSoup import BeautifulSoup          # For processing HTML
</span></span><span style="display:flex;"><span>import urllib2
</span></span><span style="display:flex;"><span>from advert import advert
</span></span><span style="display:flex;"><span>import time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>class scrapeAdvert:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        page = &#34;&#34;
</span></span><span style="display:flex;"><span>        soup = &#34;&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def scrape(self,advertURL):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                # give it a bit of time so gumtree doesn&#39;t
</span></span><span style="display:flex;"><span>                # ban us
</span></span><span style="display:flex;"><span>                time.sleep(2)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                url = advertURL
</span></span><span style="display:flex;"><span>                # print &#34;-- scraping &#34;+url+&#34; --&#34;
</span></span><span style="display:flex;"><span>                page = urllib2.urlopen(url)
</span></span><span style="display:flex;"><span>                self.soup = BeautifulSoup(page)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                self.anAd = advert()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                self.anAd.url = url
</span></span><span style="display:flex;"><span>                self.anAd.title = self.extractTitle()
</span></span><span style="display:flex;"><span>                self.anAd.pricePW = self.extractPricePW()
</span></span><span style="display:flex;"><span>                self.anAd.pricePCM = self.extractPricePCM()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                self.anAd.location = self.extractLocation()
</span></span><span style="display:flex;"><span>                self.anAd.dateAvailable = self.extractDateAvailable()
</span></span><span style="display:flex;"><span>                self.anAd.propertyType = self.extractPropertyType()
</span></span><span style="display:flex;"><span>                self.anAd.bedroomNumber = self.extractBedroomNumber()
</span></span><span style="display:flex;"><span>                self.anAd.description = self.extractDescription()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractTitle(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                location = self.soup.find(&#39;h1&#39;)
</span></span><span style="display:flex;"><span>                string = location.contents[0]
</span></span><span style="display:flex;"><span>                stripped = &#39; &#39;.join(string.split())
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#34;&#39;&#34;,&#39;&#34;&#39;)
</span></span><span style="display:flex;"><span>                # print &#39;|&#39; + stripped + &#39;|&#39;
</span></span><span style="display:flex;"><span>                return stripped
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractPricePCM(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                location = self.soup.find(&#39;span&#39;,attrs={&#34;class&#34; : &#34;price&#34;})
</span></span><span style="display:flex;"><span>                try:
</span></span><span style="display:flex;"><span>                        string = location.contents[0]
</span></span><span style="display:flex;"><span>                        string.index(&#39;pcm&#39;)
</span></span><span style="display:flex;"><span>                except AttributeError: # for ads with no prices set
</span></span><span style="display:flex;"><span>                        return 0
</span></span><span style="display:flex;"><span>                except ValueError: # for ads with pw specified
</span></span><span style="display:flex;"><span>                        return 0
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                stripped = string.replace(&#39;Â£&#39;,&#39;&#39;)
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#39;pcm&#39;,&#39;&#39;)
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#39;,&#39;,&#39;&#39;)
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#34;&#39;&#34;,&#39;&#34;&#39;)
</span></span><span style="display:flex;"><span>                stripped = &#39; &#39;.join(stripped.split())
</span></span><span style="display:flex;"><span>                # print &#39;|&#39; + stripped + &#39;|&#39;
</span></span><span style="display:flex;"><span>                return int(stripped)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractPricePW(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                location = self.soup.find(&#39;span&#39;,attrs={&#34;class&#34; : &#34;price&#34;})
</span></span><span style="display:flex;"><span>                try:
</span></span><span style="display:flex;"><span>                        string = location.contents[0]
</span></span><span style="display:flex;"><span>                        string.index(&#39;pw&#39;)
</span></span><span style="display:flex;"><span>                except AttributeError: # for ads with no prices set
</span></span><span style="display:flex;"><span>                        return 0
</span></span><span style="display:flex;"><span>                except ValueError: # for ads with pcm specified
</span></span><span style="display:flex;"><span>                        return 0
</span></span><span style="display:flex;"><span>                stripped = string.replace(&#39;Â£&#39;,&#39;&#39;)
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#39;pw&#39;,&#39;&#39;)
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#39;,&#39;,&#39;&#39;)
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#34;&#39;&#34;,&#39;&#34;&#39;)
</span></span><span style="display:flex;"><span>                stripped = &#39; &#39;.join(stripped.split())
</span></span><span style="display:flex;"><span>                # print &#39;|&#39; + stripped + &#39;|&#39;
</span></span><span style="display:flex;"><span>                return int(stripped)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractLocation(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                location = self.soup.find(&#39;span&#39;,attrs={&#34;class&#34; : &#34;location&#34;})
</span></span><span style="display:flex;"><span>                string = location.contents[0]
</span></span><span style="display:flex;"><span>                stripped = &#39; &#39;.join(string.split())
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#34;&#39;&#34;,&#39;&#34;&#39;)
</span></span><span style="display:flex;"><span>                # print &#39;|&#39; + stripped + &#39;|&#39;
</span></span><span style="display:flex;"><span>                return stripped
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractDateAvailable(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                current_year = &#39;2011&#39;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                ul = self.soup.find(&#39;ul&#39;,attrs={&#34;id&#34; : &#34;ad-details&#34;})
</span></span><span style="display:flex;"><span>                firstP = ul.findAll(&#39;p&#39;)[0]
</span></span><span style="display:flex;"><span>                string = firstP.contents[0]
</span></span><span style="display:flex;"><span>                stripped = &#39; &#39;.join(string.split())
</span></span><span style="display:flex;"><span>                date_to_convert = stripped + &#39;/&#39;+current_year
</span></span><span style="display:flex;"><span>                try:
</span></span><span style="display:flex;"><span>                        date_object = time.strptime(date_to_convert, &#34;%d/%m/%Y&#34;)
</span></span><span style="display:flex;"><span>                except ValueError: # for adverts with no date available
</span></span><span style="display:flex;"><span>                        return &#34;&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                full_date = time.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;, date_object)
</span></span><span style="display:flex;"><span>                # print &#39;|&#39; + full_date + &#39;|&#39;
</span></span><span style="display:flex;"><span>                return full_date
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractPropertyType(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                ul = self.soup.find(&#39;ul&#39;,attrs={&#34;id&#34; : &#34;ad-details&#34;})
</span></span><span style="display:flex;"><span>                try:
</span></span><span style="display:flex;"><span>                        secondP = ul.findAll(&#39;p&#39;)[1]
</span></span><span style="display:flex;"><span>                except IndexError: # for properties with no type
</span></span><span style="display:flex;"><span>                        return &#34;&#34;
</span></span><span style="display:flex;"><span>                string = secondP.contents[0]
</span></span><span style="display:flex;"><span>                stripped = &#39; &#39;.join(string.split())
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#34;&#39;&#34;,&#39;&#34;&#39;)
</span></span><span style="display:flex;"><span>                # print &#39;|&#39; + stripped + &#39;|&#39;
</span></span><span style="display:flex;"><span>                return stripped
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractBedroomNumber(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                ul = self.soup.find(&#39;ul&#39;,attrs={&#34;id&#34; : &#34;ad-details&#34;})
</span></span><span style="display:flex;"><span>                try:
</span></span><span style="display:flex;"><span>                        thirdP = ul.findAll(&#39;p&#39;)[2]
</span></span><span style="display:flex;"><span>                except IndexError: # for properties with no bedroom number
</span></span><span style="display:flex;"><span>                        return 0
</span></span><span style="display:flex;"><span>                string = thirdP.contents[0]
</span></span><span style="display:flex;"><span>                stripped = &#39; &#39;.join(string.split())
</span></span><span style="display:flex;"><span>                stripped = stripped.replace(&#34;&#39;&#34;,&#39;&#34;&#39;)
</span></span><span style="display:flex;"><span>                # print &#39;|&#39; + stripped + &#39;|&#39;
</span></span><span style="display:flex;"><span>                return stripped
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractDescription(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                div = self.soup.find(&#39;div&#39;,attrs={&#34;id&#34; : &#34;description&#34;})
</span></span><span style="display:flex;"><span>                description = div.find(&#39;p&#39;)
</span></span><span style="display:flex;"><span>                contents = description.renderContents()
</span></span><span style="display:flex;"><span>                contents = contents.replace(&#34;&#39;&#34;,&#39;&#34;&#39;)
</span></span><span style="display:flex;"><span>                # print &#39;|&#39; + contents + &#39;|&#39;
</span></span><span style="display:flex;"><span>                return contents
</span></span></code></pre></div><p>In scrapeAdvert.py there are a lot of string manipulation statements to pull out any unwanted characters, such as the &lsquo;pw&rsquo; characters (short for per week) found in the price string, which we need to remove in order to store the property price per week as an integer.</p>
<p>Using BeautifulSoup to pull out elements is quite easy, for example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>ul = self.soup.find(&#39;ul&#39;,attrs={&#34;id&#34; : &#34;ad-details&#34;})
</span></span></code></pre></div><p>That finds all the HTML elements under the tag id=&ldquo;ad-details&rdquo;, so all the list elements in that list. More detail can be found in the <a href="http://www.crummy.com/software/BeautifulSoup/documentation.html">Beautiful Soup documentation</a> which is very good.</p>
<p><strong>scrapeListing.py:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>from BeautifulSoup import BeautifulSoup          # For processing HTML
</span></span><span style="display:flex;"><span>import urllib2
</span></span><span style="display:flex;"><span>from listing import listing
</span></span><span style="display:flex;"><span>import time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>class scrapeListing:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        soup = &#34;&#34;
</span></span><span style="display:flex;"><span>        url = &#34;&#34;
</span></span><span style="display:flex;"><span>        aListing = &#34;&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def scrape(self,url):
</span></span><span style="display:flex;"><span>                # give it a bit of time so gumtree doesn&#39;t
</span></span><span style="display:flex;"><span>                # ban us
</span></span><span style="display:flex;"><span>                time.sleep(3)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                print &#34;scraping url = &#34;+str(url)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                page = urllib2.urlopen(url)
</span></span><span style="display:flex;"><span>                self.soup = BeautifulSoup(page)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                self.aListing = listing()
</span></span><span style="display:flex;"><span>                self.aListing.url = url
</span></span><span style="display:flex;"><span>                self.aListing.adverturls = self.extractAdvertURLs()
</span></span><span style="display:flex;"><span>                self.aListing.nextLink = self.extractNextLink()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractAdvertURLs(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                toReturn = []
</span></span><span style="display:flex;"><span>                h3s = self.soup.findAll(&#34;h3&#34;)
</span></span><span style="display:flex;"><span>                for h3 in h3s:
</span></span><span style="display:flex;"><span>                        links = h3.findAll(&#39;a&#39;,{&#34;class&#34;:&#34;summary&#34;})
</span></span><span style="display:flex;"><span>                        for link in links:
</span></span><span style="display:flex;"><span>                                print &#34;|&#34;+link[&#39;href&#39;]+&#34;|&#34;
</span></span><span style="display:flex;"><span>                                toReturn.append(link[&#39;href&#39;])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                return toReturn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def extractNextLink(self):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                links = self.soup.findAll(&#34;a&#34;,{&#34;class&#34;:&#34;next&#34;})
</span></span><span style="display:flex;"><span>                try:
</span></span><span style="display:flex;"><span>                        print &#34;&gt;&#34;+links[0][&#39;href&#39;]+&#34;&gt;&#34;
</span></span><span style="display:flex;"><span>                except IndexError: # if there is no &#39;next&#39; link found..
</span></span><span style="display:flex;"><span>                        return &#34;&#34;
</span></span><span style="display:flex;"><span>                return links[0][&#39;href&#39;]
</span></span></code></pre></div><p>The extractNextLink method here extracts the pagination &rsquo;next&rsquo; link which will bring up the next listing page from the selection of listing pages to browse. We use it to step through the pagination &lsquo;sequence&rsquo; of resultant listing pages.</p>
<p><strong>scrapeSequence.py:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>from scrapeListing import scrapeListing
</span></span><span style="display:flex;"><span>from scrapeAdvert import scrapeAdvert
</span></span><span style="display:flex;"><span>from listing import listing
</span></span><span style="display:flex;"><span>from advert import advert
</span></span><span style="display:flex;"><span>import MySQLdb
</span></span><span style="display:flex;"><span>import _mysql_exceptions
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># change this to the gumtree page you want to start scraping from
</span></span><span style="display:flex;"><span>url = &#34;http://www.gumtree.com/flats-and-houses-for-rent/salford-quays&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>while url != None:
</span></span><span style="display:flex;"><span>        print &#34;scraping URL = &#34;+url
</span></span><span style="display:flex;"><span>        sl = &#34;&#34;
</span></span><span style="display:flex;"><span>        sl = scrapeListing()
</span></span><span style="display:flex;"><span>        sl.scrape(url)
</span></span><span style="display:flex;"><span>        for advertURL in sl.aListing.adverturls:
</span></span><span style="display:flex;"><span>                sa = &#34;&#34;
</span></span><span style="display:flex;"><span>                sa = scrapeAdvert()
</span></span><span style="display:flex;"><span>                sa.scrape(advertURL)
</span></span><span style="display:flex;"><span>                try:
</span></span><span style="display:flex;"><span>                        sa.anAd.save()
</span></span><span style="display:flex;"><span>                except _mysql_exceptions.IntegrityError:
</span></span><span style="display:flex;"><span>                        print &#34;** Advert &#34; + sa.anAd.url + &#34; already saved **&#34;
</span></span><span style="display:flex;"><span>                sa.onAd = &#34;&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        url = &#34;&#34;
</span></span><span style="display:flex;"><span>        if sl.aListing.nextLink:
</span></span><span style="display:flex;"><span>                print &#34;nextLink = &#34;+sl.aListing.nextLink
</span></span><span style="display:flex;"><span>                url = sl.aListing.nextLink
</span></span><span style="display:flex;"><span>        else:
</span></span><span style="display:flex;"><span>                print &#39;all done.&#39;
</span></span><span style="display:flex;"><span>                break
</span></span></code></pre></div><p>This is the file you run to kick off the scrape. It uses an MySQL IntegrityError try/except block to pick out when an advert has already been entered into the database, this will throw an error because the URL of the advert is the primary key in the database. So no two records can have the same primary key.</p>
<p>The URL you provide it above gives you the starting page from which to scrape from.</p>
<p>The above code worked well for scraping several hundred Manchester Gumtree ads into a database, from which point I was able to use a combination of phpMyAdmin and OpenOffice Spreadsheet to analyse the data and find out useful statistics about the property market in said area.</p>
<p><a href="http://www.davidcraddock.net/uploads/gumtree-scraper.tgz">Download the scraper source code in a tar.gz archive</a></p>
<p>Note: Due to the nature of web scraping, if - or more accurately, when - Gumtree changes its user interface, the scraper I have written will need to be tweaked accordingly to find the right data. This is meant to be an informative tutorial, not a finished product.</p>


  </div>

  <footer class="post-footer">
  </footer>
    <div class="comments-separator"></div>
</article>
    </main>
    
<footer class="footer">
  <span>&copy; 2024 <a href="http://192.168.1.50:9796/">DavidCraddock.net</a></span><span style="display: inline-block; margin-left: 1em;">
    <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a>
  </span>
  <span style="display: inline-block; margin-left: 1em;">
    Powered by
    <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
    <a href="https://github.com/reorx/hugo-PaperModX/" rel="noopener" target="_blank">PaperModX</a>
  </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
    <path d="M12 6H0l6-6z" />
  </svg>
</a>

<script>
  (function() {
     
    const disableThemeToggle = '1' == '1';
    if (disableThemeToggle) {
      return;
    }

    let button = document.getElementById("theme-toggle")
    
    button.removeEventListener('click', toggleThemeListener)
    
    button.addEventListener('click', toggleThemeListener)
  })();
</script>

<script>
  (function () {
    let menu = document.getElementById('menu')
    if (menu) {
      menu.scrollLeft = localStorage.getItem("menu-scroll-position");
      menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
      }
    }

    const disableSmoothScroll = '' == '1';
    const enableInstantClick = '1' == '1';
    
    if (window.matchMedia('(prefers-reduced-motion: reduce)').matches || disableSmoothScroll || enableInstantClick) {
      return;
    }
    
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener("click", function (e) {
        e.preventDefault();
        var id = this.getAttribute("href").substr(1);
        document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
          behavior: "smooth"
        });
        if (id === "top") {
          history.replaceState(null, null, " ");
        } else {
          history.pushState(null, null, `#${id}`);
        }
      });
    });
  })();
</script>
<script>
  var mybutton = document.getElementById("top-link");
  window.onscroll = function () {
    if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
      mybutton.style.visibility = "visible";
      mybutton.style.opacity = "1";
    } else {
      mybutton.style.visibility = "hidden";
      mybutton.style.opacity = "0";
    }
  };
</script>
<script>
  if (window.scrollListeners) {
    
    for (const listener of scrollListeners) {
      window.removeEventListener('scroll', listener)
    }
  }
  window.scrollListeners = []
</script>



<script src="/js/medium-zoom.min.js" data-no-instant
></script>
<script>
  document.querySelectorAll('pre > code').forEach((codeblock) => {
    const container = codeblock.parentNode.parentNode;

    const copybutton = document.createElement('button');
    copybutton.classList.add('copy-code');
    copybutton.innerText = 'copy';

    function copyingDone() {
      copybutton.innerText = 'copied!';
      setTimeout(() => {
        copybutton.innerText = 'copy';
      }, 2000);
    }

    copybutton.addEventListener('click', (cb) => {
      if ('clipboard' in navigator) {
        navigator.clipboard.writeText(codeblock.textContent);
        copyingDone();
        return;
      }

      const range = document.createRange();
      range.selectNodeContents(codeblock);
      const selection = window.getSelection();
      selection.removeAllRanges();
      selection.addRange(range);
      try {
        document.execCommand('copy');
        copyingDone();
      } catch (e) { };
      selection.removeRange(range);
    });

    if (container.classList.contains("highlight")) {
      container.appendChild(copybutton);
    } else if (container.parentNode.firstChild == container) {
      
    } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
      
      codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
    } else {
      
      codeblock.parentNode.appendChild(copybutton);
    }
  });
</script>




<script>
  
  
  (function() {
    const enableTocScroll = '1' == '1'
    if (!enableTocScroll) {
      return
    }
    if (!document.querySelector('.toc')) {
      console.log('no toc found, ignore toc scroll')
      return
    }
    

    
    const scrollListeners = window.scrollListeners
    const headings = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id]');
    const activeClass = 'active';

    
    let activeHeading = headings[0];
    getLinkByHeading(activeHeading).classList.add(activeClass);

    const onScroll = () => {
      const passedHeadings = [];
      for (const h of headings) {
        
        if (getOffsetTop(h) < 5) {
          passedHeadings.push(h)
        } else {
          break;
        }
      }
      if (passedHeadings.length > 0) {
        newActiveHeading = passedHeadings[passedHeadings.length - 1];
      } else {
        newActiveHeading = headings[0];
      }
      if (activeHeading != newActiveHeading) {
        getLinkByHeading(activeHeading).classList.remove(activeClass);
        activeHeading = newActiveHeading;
        getLinkByHeading(activeHeading).classList.add(activeClass);
      }
    }

    let timer = null;
    const scrollListener = () => {
      if (timer !== null) {
        clearTimeout(timer)
      }
      timer = setTimeout(onScroll, 50)
    }
    window.addEventListener('scroll', scrollListener, false);
    scrollListeners.push(scrollListener)

    function getLinkByHeading(heading) {
      const id = encodeURI(heading.getAttribute('id')).toLowerCase();
      return document.querySelector(`.toc ul li a[href="#${id}"]`);
    }

    function getOffsetTop(heading) {
      if (!heading.getClientRects().length) {
        return 0;
      }
      let rect = heading.getBoundingClientRect();
      return rect.top
    }
  })();
  </script>

<script src="/js/instantclick.js" data-no-instant
></script>
<script data-no-instant>
  
  
  
  
  
  
  InstantClick.init();
</script>
</body>

</html>
